--- linux-3.3.8/net/core/skbuff.c.orig	2013-03-11 19:36:29.000000000 +0800
+++ linux-3.3.8/net/core/skbuff.c	2013-03-13 21:00:48.348879991 +0800
@@ -505,7 +505,17 @@
 
 void __kfree_skb(struct sk_buff *skb)
 {
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	skb_release_head_state(skb);
+	if (skb->skb_recycling_callback) {
+		if (skb->skb_recycling_callback(skb))
+			return;
+	}
+	skb->skb_recycling_callback = NULL;
+	skb_release_data(skb);
+#else
 	skb_release_all(skb);
+#endif
 	kfree_skbmem(skb);
 }
 EXPORT_SYMBOL(__kfree_skb);
@@ -636,7 +646,9 @@
 #endif
 #endif
 	new->vlan_tci		= old->vlan_tci;
-
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	new->skb_recycling_callback = NULL;
+#endif
 	skb_copy_secmark(new, old);
 }
 
@@ -659,6 +671,10 @@
 	n->cloned = 1;
 	n->nohdr = 0;
 	n->destructor = NULL;
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	n->skb_recycling_callback = NULL;
+	skb->skb_recycling_callback = NULL;
+#endif
 	C(tail);
 	C(end);
 	C(head);
@@ -997,7 +1013,10 @@
 
 		if (skb_has_frag_list(skb))
 			skb_clone_fraglist(skb);
-
+		
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	skb->skb_recycling_callback = NULL;
+#endif
 		skb_release_data(skb);
 	}
 	off = (data + nhead) - skb->head;
@@ -2850,6 +2869,207 @@
 }
 EXPORT_SYMBOL_GPL(skb_segment);
 
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+
+#define SKBMGR_RX_BUF_LEN                       SKB_WITH_OVERHEAD(2048)
+#define SKBMGR_DEF_HOT_LIST_LEN                 512
+
+int skbmgr_hot_list_len = SKBMGR_DEF_HOT_LIST_LEN;
+int skbmgr_max_list_len = 0;
+
+struct sk_buff_head		rx0_recycle;
+
+struct sk_buff *skbmgr_alloc_skb2k(void)
+{
+        struct sk_buff *skb;
+	unsigned long flags;
+
+        if (skb_queue_len(&rx0_recycle)) {
+                unsigned int size;
+                struct skb_shared_info *shinfo;
+                u8 *data;
+
+		local_irq_save(flags);
+                skb = __skb_dequeue_tail(&rx0_recycle);
+		local_irq_restore(flags);
+
+                if (unlikely(skb == NULL))
+                        goto try_normal;
+                
+		size = skb->truesize - sizeof(struct sk_buff);
+                data = skb->head;
+		
+		/*
+                 * See comment in sk_buff definition, just before the 'tail' member
+                 */
+                memset(skb, 0, offsetof(struct sk_buff, tail));
+                skb->truesize = size + sizeof(struct sk_buff);
+                atomic_set(&skb->users, 1);
+                skb->head = data;
+                skb->data = data;
+                skb_reset_tail_pointer(skb);
+                skb->end = skb->tail + size;
+                /* make sure we initialize shinfo sequentially */
+                shinfo = skb_shinfo(skb);
+                atomic_set(&shinfo->dataref, 1);
+                shinfo->nr_frags  = 0;
+                shinfo->gso_size = 0;
+                shinfo->gso_segs = 0;
+                shinfo->gso_type = 0;
+                shinfo->ip6_frag_id = 0;
+                shinfo->frag_list = NULL;
+                skb->skb_recycling_callback = skbmgr_recycling_callback;
+
+                return skb;
+        }
+
+try_normal:
+        skb = alloc_skb(SKBMGR_RX_BUF_LEN, GFP_ATOMIC|__GFP_NOWARN);
+        if (likely(skb))
+                skb->skb_recycling_callback = skbmgr_recycling_callback;
+        return skb;
+}
+
+EXPORT_SYMBOL(skbmgr_alloc_skb2k);
+
+int skbmgr_recycling_callback(struct sk_buff *skb)
+{
+
+	unsigned long flags;
+        
+	if (skb_queue_len(&rx0_recycle) < skbmgr_hot_list_len) {
+
+                if ((skb->truesize - sizeof(struct sk_buff) != SKBMGR_RX_BUF_LEN) ||
+                        (skb_shinfo(skb)->nr_frags) ||
+                        (skb_shinfo(skb)->frag_list)) {
+                        return 0;
+                }
+
+                if (skb_queue_len(&rx0_recycle) > skbmgr_max_list_len)
+                        skbmgr_max_list_len = skb_queue_len(&rx0_recycle) + 1;
+
+		local_irq_save(flags);
+                __skb_queue_head(&rx0_recycle, skb);
+		local_irq_restore(flags);
+
+                return 1;
+        }
+
+        return 0;
+}
+
+EXPORT_SYMBOL(skbmgr_recycling_callback);
+
+void skbmgr_free_all_skbs(void)
+{
+        struct sk_buff *skb;
+        int i;
+
+        for (i=0; i<NR_CPUS; i++) {
+                while ((skb = skb_dequeue(&rx0_recycle)) != NULL) {
+                        skb->skb_recycling_callback = NULL;
+                        kfree_skbmem(skb);
+                }
+        }
+
+}
+
+#ifdef CONFIG_PROC_FS
+static int hot_list_len_read(char *page, char **start, off_t offset,
+                            int count, int *eof, void *data)
+{
+        char *out = page;
+        int len;
+
+        out += sprintf(out, "skbmgr_hot_list_len %d\n", skbmgr_hot_list_len);
+
+        len = out - page;
+        len -= offset;
+        if (len < count) {
+                *eof = 1;
+                if (len <= 0)
+                        return 0;
+        } else
+                len = count;
+
+        *start = page + offset;
+        return len;
+}
+
+static int hot_list_len_write(struct file *file, const char __user * buffer,
+                             unsigned long count, void *data)
+{
+        char buf[64];
+        int val;
+
+        if (count > 64)
+                return -EINVAL;
+
+        if (copy_from_user(buf, buffer, count))
+                return -EFAULT;
+
+        val = simple_strtoul(buf, NULL, 10);
+
+        skbmgr_hot_list_len = val;
+        if (skbmgr_hot_list_len == 0) {
+                skbmgr_free_all_skbs();
+                skbmgr_max_list_len = 0;
+        }
+
+        return count;
+}
+
+static int skbmgr_info_read(char *page, char **start, off_t offset,
+                            int count, int *eof, void *data)
+{
+        char *out = page;
+        int len;
+
+        out += sprintf(out, "skbmgr_max_list_len = %d\n", skbmgr_max_list_len);
+	out += sprintf(out, "skbmgr_queue_len = %d\n", skb_queue_len(&rx0_recycle));
+
+
+        len = out - page;
+        len -= offset;
+        if (len < count) {
+                *eof = 1;
+                if (len <= 0)
+                        return 0;
+        } else
+                len = count;
+
+        *start = page + offset;
+        return len;
+}
+static int register_proc_skbmgr(void)
+{
+        struct proc_dir_entry *p;
+
+        p = create_proc_entry("skbmgr_hot_list_len", 0644, init_net.proc_net);
+        if (!p)
+                return 0;
+
+        p->read_proc = hot_list_len_read;
+        p->write_proc = hot_list_len_write;
+
+        p = create_proc_read_entry("skbmgr_info", 0, init_net.proc_net, skbmgr_info_read, NULL);
+        if (!p)
+                return 0;
+
+        return 1;
+}
+
+#if 0
+static void unregister_proc_skbmgr(void)
+{
+        remove_proc_entry("skbmgr_hot_list_len", init_net.proc_net);
+        remove_proc_entry("skbmgr_info", init_net.proc_net);
+}
+#endif
+
+#endif
+
+#endif
 int skb_gro_receive(struct sk_buff **head, struct sk_buff *skb)
 {
 	struct sk_buff *p = *head;
@@ -2964,6 +3184,12 @@
 
 void __init skb_init(void)
 {
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	skb_queue_head_init(&rx0_recycle);
+#ifdef CONFIG_PROC_FS
+        register_proc_skbmgr();
+#endif
+#endif
 	skbuff_head_cache = kmem_cache_create("skbuff_head_cache",
 					      sizeof(struct sk_buff),
 					      0,
--- linux-3.3.8/include/linux/skbuff.h.orig	2013-03-13 20:44:04.000000000 +0800
+++ linux-3.3.8/include/linux/skbuff.h	2013-03-13 20:44:19.248865329 +0800
@@ -427,6 +427,10 @@
 	__be16			protocol;
 
 	void			(*destructor)(struct sk_buff *skb);
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+	int                     (*skb_recycling_callback)(struct sk_buff *skb);
+#endif	
+	
 #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
 	struct nf_conntrack	*nfct;
 #endif
@@ -2468,6 +2472,19 @@
 	return skb_shinfo(skb)->gso_type & SKB_GSO_TCPV6;
 }
 
+#if defined(CONFIG_RAETH_SKB_RECYCLE_2K)
+struct sk_buff *skbmgr_alloc_skb2k(void);
+int skbmgr_recycling_callback(struct sk_buff *skb);
+
+static inline struct sk_buff *skbmgr_dev_alloc_skb2k(void)
+{
+        struct sk_buff *skb = skbmgr_alloc_skb2k();
+        if (likely(skb))
+                skb_reserve(skb, NET_SKB_PAD);
+        return skb;
+}
+#endif
+
 extern void __skb_warn_lro_forwarding(const struct sk_buff *skb);
 
 static inline bool skb_warn_if_lro(const struct sk_buff *skb)
